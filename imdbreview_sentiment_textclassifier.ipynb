{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The script classifies movie reviews as positive or negative using the text of the review. This is an example of binary—or two-class—classification.\n",
    "The dataset used is IMDB dataset having 50K reviews. 25k each for trainig and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset comes packaged with TensorFlow. It has already been preprocessed such that the reviews (sequences of words) have been converted to sequences of integers, where each integer represents a specific word in a dictionary.\n",
    "(not good for learning :-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 15s 1us/step\n"
     ]
    }
   ],
   "source": [
    "imdb_data = keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb_data.load_data(num_words=10000)\n",
    "#The argument num_words=10000 keeps the top 10,000 most frequently occurring words in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For exploring a little bit, it is important to convert integers back to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "word_index = imdb_data.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> shown in australia as <UNK> this incredibly bad movie is so bad that you become <UNK> and have to watch it to the end just to see if it could get any worse and it does the storyline is so predictable it seems written by a high school <UNK> class the sets are pathetic but <UNK> better than the <UNK> and the acting is wooden br br the <UNK> <UNK> seems to have been stolen from the props <UNK> of <UNK> <UNK> there didn't seem to be a single original idea in the whole movie br br i found this movie to be so bad that i laughed most of the way through br br malcolm mcdowell should hang his head in shame he obviously needed the money\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#label 0 for negative review and label 1 for positive reviews."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The reviews—the arrays of integers—must be converted to tensors before fed into the neural network. This conversion can be done a couple of ways:\n",
    "\n",
    "-Convert the arrays into vectors of 0s and 1s indicating word occurrence, similar to a one-hot encoding. \n",
    "    For example, the sequence [3, 5] would become a 10,000-dimensional vector that is all zeros except for indices 3 and 5, \n",
    "    which are ones. Then, make this the first layer in our network—a Dense layer—that can handle floating point vector data. \n",
    "    This approach is memory intensive, though, requiring a num_words * num_reviews size matrix.\n",
    "\n",
    "-Alternatively, we can pad the arrays so they all have the same length, then create an integer tensor\n",
    "    of shape max_length * num_reviews. We can use an embedding layer capable of handling this shape \n",
    "    as the first layer in our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get with the second way as the first one is so computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the movie reviews must be the same length, we will use the pad_sequences function to standardize the lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 #the input dimension will be equal to the vocabulary size\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "-The first layer is an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n",
    "-Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "-This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
    "-The last layer is densely connected with a single output node. Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability, or confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this is a binary classification problem and the model outputs a probability \n",
    "#(a single-unit layer with a sigmoid activation), we'll use the binary_crossentropy loss function.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.6900 - acc: 0.6602 - val_loss: 0.6848 - val_acc: 0.7064\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.6770 - acc: 0.7461 - val_loss: 0.6653 - val_acc: 0.7540\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.6490 - acc: 0.7750 - val_loss: 0.6284 - val_acc: 0.7796\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.6022 - acc: 0.8028 - val_loss: 0.5757 - val_acc: 0.8018\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.5415 - acc: 0.8290 - val_loss: 0.5175 - val_acc: 0.8138\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.4772 - acc: 0.8487 - val_loss: 0.4598 - val_acc: 0.8398\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.4202 - acc: 0.8658 - val_loss: 0.4154 - val_acc: 0.8562\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.3732 - acc: 0.8790 - val_loss: 0.3810 - val_acc: 0.8622\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.3375 - acc: 0.8866 - val_loss: 0.3577 - val_acc: 0.8610\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.3082 - acc: 0.8943 - val_loss: 0.3372 - val_acc: 0.8714\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.2854 - acc: 0.9025 - val_loss: 0.3239 - val_acc: 0.8730\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.2668 - acc: 0.9067 - val_loss: 0.3137 - val_acc: 0.8766\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.2506 - acc: 0.9117 - val_loss: 0.3060 - val_acc: 0.8778\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.2362 - acc: 0.9167 - val_loss: 0.2980 - val_acc: 0.8820\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.2236 - acc: 0.9215 - val_loss: 0.2926 - val_acc: 0.8814\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.2123 - acc: 0.9248 - val_loss: 0.2886 - val_acc: 0.8856\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.2018 - acc: 0.9293 - val_loss: 0.2854 - val_acc: 0.8878\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.1924 - acc: 0.9321 - val_loss: 0.2836 - val_acc: 0.8870\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 34us/step - loss: 0.1838 - acc: 0.9359 - val_loss: 0.2814 - val_acc: 0.8890\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 38us/step - loss: 0.1756 - acc: 0.9391 - val_loss: 0.2805 - val_acc: 0.8882\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1678 - acc: 0.9423 - val_loss: 0.2805 - val_acc: 0.8884\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.1611 - acc: 0.9443 - val_loss: 0.2796 - val_acc: 0.8894\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.1556 - acc: 0.9472 - val_loss: 0.2811 - val_acc: 0.8902\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.1483 - acc: 0.9499 - val_loss: 0.2832 - val_acc: 0.8866\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.1430 - acc: 0.9518 - val_loss: 0.2835 - val_acc: 0.8892\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 35us/step - loss: 0.1371 - acc: 0.9539 - val_loss: 0.2850 - val_acc: 0.8886\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.1321 - acc: 0.9573 - val_loss: 0.2876 - val_acc: 0.8882\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.1275 - acc: 0.9584 - val_loss: 0.2894 - val_acc: 0.8884\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.1224 - acc: 0.9614 - val_loss: 0.2921 - val_acc: 0.8892\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.1178 - acc: 0.9632 - val_loss: 0.2951 - val_acc: 0.8876\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.1136 - acc: 0.9651 - val_loss: 0.2974 - val_acc: 0.8874\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 37us/step - loss: 0.1091 - acc: 0.9665 - val_loss: 0.3008 - val_acc: 0.8862\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.1053 - acc: 0.9686 - val_loss: 0.3049 - val_acc: 0.8860\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.1019 - acc: 0.9693 - val_loss: 0.3094 - val_acc: 0.8862\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.0983 - acc: 0.9709 - val_loss: 0.3119 - val_acc: 0.8846\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0944 - acc: 0.9724 - val_loss: 0.3161 - val_acc: 0.8852\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0912 - acc: 0.9738 - val_loss: 0.3210 - val_acc: 0.8846\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.0874 - acc: 0.9748 - val_loss: 0.3247 - val_acc: 0.8828\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0843 - acc: 0.9765 - val_loss: 0.3296 - val_acc: 0.8842\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0818 - acc: 0.9774 - val_loss: 0.3342 - val_acc: 0.8842\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 32us/step - loss: 0.0788 - acc: 0.9788 - val_loss: 0.3406 - val_acc: 0.8824\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0764 - acc: 0.9796 - val_loss: 0.3453 - val_acc: 0.8842\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0744 - acc: 0.9806 - val_loss: 0.3490 - val_acc: 0.8844\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0705 - acc: 0.9824 - val_loss: 0.3543 - val_acc: 0.8838\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 28us/step - loss: 0.0680 - acc: 0.9834 - val_loss: 0.3601 - val_acc: 0.8820\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0655 - acc: 0.9845 - val_loss: 0.3656 - val_acc: 0.8812\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 35us/step - loss: 0.0633 - acc: 0.9855 - val_loss: 0.3711 - val_acc: 0.8832\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0617 - acc: 0.9856 - val_loss: 0.3781 - val_acc: 0.8796\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 36us/step - loss: 0.0591 - acc: 0.9859 - val_loss: 0.3821 - val_acc: 0.8814\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0570 - acc: 0.9868 - val_loss: 0.3893 - val_acc: 0.8794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 40us/step\n",
      "[0.4266794769096375, 0.8638]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n",
    "plt.title('Training and validation Acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Important:\n",
    "    \n",
    "The training accuracy increases with each epoch. This is expected when using a gradient descent optimization.\n",
    "This isn't the case for the validation accuracy. They seem to peak after about twenty epochs. \n",
    "This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. \n",
    "After this point, the model over-optimizes and learns representations specific to the training data that do not generalize to test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
